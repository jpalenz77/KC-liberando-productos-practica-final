# KC Liberando Productos - Pr√°ctica Final
## Simple Server - Aplicaci√≥n FastAPI con CI/CD y Monitorizaci√≥n

[![Test](https://github.com/jpalenz77/KC-liberando-productos-practica-final/actions/workflows/test.yml/badge.svg)](https://github.com/jpalenz77/KC-liberando-productos-practica-final/actions/workflows/test.yml)
[![Release](https://github.com/jpalenz77/KC-liberando-productos-practica-final/actions/workflows/release.yml/badge.svg)](https://github.com/jpalenz77/KC-liberando-productos-practica-final/actions/workflows/release.yml)

---

## üìã Tabla de Contenidos

1. [Descripci√≥n del Proyecto](#-descripci√≥n-del-proyecto)
2. [Endpoints Implementados](#-endpoints-implementados)
3. [Tests Unitarios](#-tests-unitarios)
4. [CI/CD Pipeline](#-cicd-pipeline)
5. [Helm Chart](#-helm-chart)
6. [Monitorizaci√≥n con Prometheus](#-monitorizaci√≥n-con-prometheus)
7. [Alertas con Alertmanager](#-alertas-con-alertmanager)
8. [Dashboard de Grafana](#-dashboard-de-grafana)
9. [Gu√≠a de Despliegue](#-gu√≠a-de-despliegue)
10. [Troubleshooting](#-troubleshooting)

---

## üìñ Descripci√≥n del Proyecto

Este proyecto implementa una aplicaci√≥n web simple usando **FastAPI** con los siguientes componentes:

- **Aplicaci√≥n**: Servidor web con m√∫ltiples endpoints
- **Tests**: Cobertura del 89% con pytest
- **CI/CD**: GitHub Actions para testing y release
- **Containerizaci√≥n**: Docker image publicada en GHCR
- **Orquestaci√≥n**: Helm chart para Kubernetes
- **Monitorizaci√≥n**: Prometheus + Grafana + Alertmanager

---

## üöÄ Endpoints Implementados

La aplicaci√≥n expone los siguientes endpoints:

### 1. **GET /** - Main Endpoint
```bash
curl http://localhost:8081/
# Response: {"msg": "Hello World"}
```

### 2. **GET /bye** - Nuevo Endpoint (Pr√°ctica Final)
```bash
curl http://localhost:8081/bye
# Response: {"msg": "Bye Bye"}
```

### 3. **GET /health** - Health Check
```bash
curl http://localhost:8081/health
# Response: {"health": "ok"}
```

### 4. **GET /metrics** - M√©tricas de Prometheus
```bash
curl http://localhost:8081/metrics
# Response: m√©tricas en formato Prometheus
```

**M√©tricas expuestas:**
- `server_requests_total` - Total de peticiones al servidor
- `main_requests_total` - Peticiones al endpoint `/`
- `bye_requests_total` - Peticiones al endpoint `/bye` ‚≠ê NUEVO
- `healthcheck_requests_total` - Peticiones al endpoint `/health`

---

## üß™ Tests Unitarios

### Estructura de Tests
```
tests/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ conftest.py          # Configuraci√≥n de pytest
‚îî‚îÄ‚îÄ app_test.py          # Tests de los endpoints
```

### Tests Implementados

Los tests cubren todos los endpoints con un **89% de cobertura**:

1. ‚úÖ `test_read_health()` - Verifica endpoint `/health`
2. ‚úÖ `test_read_main()` - Verifica endpoint `/`
3. ‚úÖ `test_read_bye()` - Verifica endpoint `/bye` ‚≠ê NUEVO
4. ‚úÖ `test_metrics()` - Verifica endpoint `/metrics` y todas las m√©tricas

### Ejecutar Tests Localmente
```bash
# Crear entorno virtual
python3 -m venv venv
source venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt

# Ejecutar tests con cobertura
pytest --cov --cov-report=term -v

# Ver reporte HTML
pytest --cov --cov-report=html
open htmlcov/index.html
```

### Resultado Esperado
```
tests/app_test.py::TestSimpleServer::test_read_health PASSED      [ 25%]
tests/app_test.py::TestSimpleServer::test_read_main PASSED        [ 50%]
tests/app_test.py::TestSimpleServer::test_read_bye PASSED         [ 75%]
tests/app_test.py::TestSimpleServer::test_metrics PASSED          [100%]

---------- coverage: platform linux, python 3.12.3-final-0 -----------
Name                          Stmts   Miss  Cover
-----------------------------------------------------------
src/__init__.py                   0      0   100%
src/application/__init__.py       0      0   100%
src/application/app.py           36      4    89%
-----------------------------------------------------------
TOTAL                            36      4    89%
```

---

## üîÑ CI/CD Pipeline

El proyecto implementa dos workflows de GitHub Actions:

### 1. Testing Pipeline (`.github/workflows/test.yml`)

**Trigger:** Push o Pull Request a cualquier rama

**Pasos:**
1. Checkout del c√≥digo
2. Setup de Python 3.11.8
3. Instalaci√≥n de dependencias
4. Ejecuci√≥n de tests con coverage
5. Generaci√≥n de reportes de cobertura
6. Comentario autom√°tico en PRs con el coverage

**Ejemplo de ejecuci√≥n:**
```bash
# Ver en GitHub Actions
https://github.com/jpalenz77/KC-liberando-productos-practica-final/actions
```

**Resultado esperado:**
- ‚úÖ Tests passing
- ‚úÖ Coverage > 70%
- ‚úÖ Comentario autom√°tico en PR con cobertura

### 2. Build & Push Pipeline (`.github/workflows/release.yml`)

**Trigger:** Push de tags con formato `v*` (ejemplo: `v1.0.0`)

**Pasos:**
1. Checkout del c√≥digo
2. Setup de Docker Buildx
3. Login en GitHub Container Registry (GHCR)
4. Extracci√≥n de metadata (tags)
5. Build y push de la imagen Docker

**Estrategia de tags:**

Para un tag `v1.2.3`, se generan autom√°ticamente:
- `ghcr.io/jpalenz77/kc-liberando-productos-practica-final:1.2.3`
- `ghcr.io/jpalenz77/kc-liberando-productos-practica-final:1.2`
- `ghcr.io/jpalenz77/kc-liberando-productos-practica-final:1`
- `ghcr.io/jpalenz77/kc-liberando-productos-practica-final:latest`

**Crear un release:**
```bash
# Crear tag
git tag -a v1.0.0 -m "Release version 1.0.0"

# Push tag (dispara el workflow)
git push origin v1.0.0

# Verificar la imagen publicada
docker pull ghcr.io/jpalenz77/kc-liberando-productos-practica-final:latest
```

---

## ‚éà Helm Chart

### Estructura del Chart
```
helm/simple-server/
‚îú‚îÄ‚îÄ Chart.yaml              # Metadata del chart
‚îú‚îÄ‚îÄ values.yaml             # Valores configurables
‚îî‚îÄ‚îÄ templates/
    ‚îú‚îÄ‚îÄ _helpers.tpl        # Funciones helper
    ‚îú‚îÄ‚îÄ deployment.yaml     # Deployment con la app
    ‚îú‚îÄ‚îÄ service.yaml        # Service (ClusterIP)
    ‚îú‚îÄ‚îÄ serviceaccount.yaml # ServiceAccount
    ‚îú‚îÄ‚îÄ hpa.yaml           # HorizontalPodAutoscaler
    ‚îú‚îÄ‚îÄ ingress.yaml       # Ingress (opcional)
    ‚îú‚îÄ‚îÄ service_monitor.yaml # ServiceMonitor (Prometheus)
    ‚îî‚îÄ‚îÄ dockerhub_access.yaml # Secret para GHCR
```

### Caracter√≠sticas del Chart

- ‚úÖ **Deployment**: 1-100 r√©plicas con autoscaling
- ‚úÖ **Service**: Expone puerto 8081 (app) y 8000 (metrics)
- ‚úÖ **HPA**: Autoscaling basado en CPU (70%) y memoria (70%)
- ‚úÖ **ServiceMonitor**: Integraci√≥n autom√°tica con Prometheus
- ‚úÖ **Health Checks**: Liveness y Readiness probes
- ‚úÖ **Resources**: Limits y requests configurados

### Instalaci√≥n del Chart
```bash
# A√±adir repositorio de Helm (si a√∫n no est√°)
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# Instalar la aplicaci√≥n
helm install simple-server ./helm/simple-server \
  --namespace simple-server \
  --create-namespace \
  --set image.repository=ghcr.io/jpalenz77/kc-liberando-productos-practica-final \
  --set image.tag=latest
```

### Verificar el despliegue
```bash
# Ver pods
kubectl get pods -n simple-server

# Ver servicios
kubectl get svc -n simple-server

# Ver HPA
kubectl get hpa -n simple-server

# Ver ServiceMonitor
kubectl get servicemonitor -n simple-server

# Logs de la aplicaci√≥n
kubectl logs -n simple-server -l app.kubernetes.io/name=simple-server -f
```

### Port-forward para acceder
```bash
# Aplicaci√≥n
kubectl port-forward -n simple-server svc/simple-server 8081:8081

# Probar endpoints
curl http://localhost:8081/
curl http://localhost:8081/bye
curl http://localhost:8081/health
curl http://localhost:8081/metrics
```

---

## üìä Monitorizaci√≥n con Prometheus

### Instalaci√≥n de kube-prometheus-stack
```bash
# Crear namespace
kubectl create namespace monitoring

# Instalar Prometheus Operator + Grafana + Alertmanager
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --values monitoring/kube-prometheus-stack/values.yaml
```

### Verificar instalaci√≥n
```bash
# Ver todos los pods de monitoring
kubectl get pods -n monitoring

# Deber√≠as ver:
# - prometheus-operator
# - prometheus-prometheus-kube-prometheus-prometheus-0
# - alertmanager-prometheus-kube-prometheus-alertmanager-0
# - prometheus-grafana-xxx
# - prometheus-kube-state-metrics-xxx
# - prometheus-prometheus-node-exporter-xxx
```

### Acceder a Prometheus
```bash
# Port-forward
kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090

# Abrir en navegador
open http://localhost:9090
```

### Verificar que las m√©tricas se est√°n recolectando

1. Ve a **Status ‚Üí Targets**
2. Busca el job `simple-server`
3. Deber√≠a estar en estado **UP**

### Queries √∫tiles en Prometheus
```promql
# Total de requests
server_requests_total

# Rate de requests por segundo
rate(server_requests_total[5m])

# Requests al endpoint /bye
bye_requests_total

# Rate del endpoint /bye
rate(bye_requests_total[5m])

# Comparar todos los endpoints
sum by (endpoint) (rate(server_requests_total[5m]))

# Reinicios de la aplicaci√≥n
kube_pod_container_status_restarts_total{pod=~".*simple-server.*"}
```

---

## üö® Alertas con Alertmanager

### Configuraci√≥n de Slack

1. **Crear canal en Slack**: `#jpalenz-prometheus-alarms`
2. **Crear Incoming Webhook**:
   - Ve a https://api.slack.com/apps
   - Create New App ‚Üí From scratch
   - Nombre: "Prometheus Alertmanager"
   - Incoming Webhooks ‚Üí Activate ‚Üí Add New Webhook
   - Copia la URL del webhook

3. **Configurar en values.yaml**:
```yaml
   alertmanager:
     config:
       global:
         slack_api_url: 'https://hooks.slack.com/services/TU-WEBHOOK-AQUI'
       receivers:
         - name: 'slack-critical'
           slack_configs:
             - channel: '#jpalenz-prometheus-alarms'
```

### Alertas Configuradas

#### Alertas CRITICAL (üî¥):

| Alerta | Condici√≥n | Duraci√≥n |
|--------|-----------|----------|
| `SimpleServerDown` | Pod ca√≠do | 1 min |
| `SimpleServerCPUThrottlingHigh` | CPU throttling > 25% | 5 min |
| `SimpleServerConsumingMoreThanRequest` | Memoria > request | 2 min |
| `SimpleServerMemoryLimitReached` | Memoria > 90% del l√≠mite | 1 min |

#### Alertas HIGH (üü†):

| Alerta | Condici√≥n | Duraci√≥n |
|--------|-----------|----------|
| `SimpleServerCPUConsumingMoreThanRequest` | CPU > request | 2 min |
| `SimpleServerHighRequestRate` | > 100 req/s | 5 min |
| `SimpleServerNoRequests` | Sin requests | 10 min |
| `SimpleServerPodRestarting` | Pod reiniciando | 5 min |

### Probar las alertas

#### Opci√≥n 1: Escalar a 0 (SimpleServerDown)
```bash
# Escalar a 0 r√©plicas
kubectl scale deployment simple-server -n simple-server --replicas=0

# Esperar ~2 minutos ‚Üí Recibir√°s alerta en Slack

# Restaurar
kubectl scale deployment simple-server -n simple-server --replicas=2
```

#### Opci√≥n 2: Generar carga CPU
```bash
# Instalar stress
kubectl run stress-test -n simple-server \
  --image=polinux/stress \
  --rm -it --restart=Never \
  -- stress --cpu 2 --timeout 300s
```

### Acceder a Alertmanager
```bash
# Port-forward
kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-alertmanager 9093:9093

# Abrir en navegador
open http://localhost:9093
```

---

## üìà Dashboard de Grafana

### Acceder a Grafana
```bash
# Port-forward
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80

# Abrir en navegador
open http://localhost:3000

# Credenciales:
# User: admin
# Password: prom-operator
```

### Importar Dashboard

**Opci√≥n 1: Mediante ConfigMap (Autom√°tico)**
```bash
# Aplicar el ConfigMap
kubectl apply -f monitoring/grafana/simple-server-dashboard-configmap.yaml

# El dashboard aparecer√° autom√°ticamente en Grafana
```

**Opci√≥n 2: Import Manual**

1. En Grafana, click en **+** ‚Üí **Import**
2. Click en **Upload JSON file**
3. Selecciona `monitoring/grafana/dashboards/simple-server-dashboard.json`
4. Selecciona datasource: **Prometheus**
5. Click **Import**

### Paneles del Dashboard

El dashboard **"Simple Server - Application Metrics"** incluye:

#### Fila 1 - Contadores (Gauges):
1. **Total Requests** - Total de peticiones al servidor
2. **Main Endpoint (/) Calls** - Llamadas a `/`
3. **Bye Endpoint (/bye) Calls** - Llamadas a `/bye` ‚≠ê
4. **Application Restarts** - N√∫mero de reinicios ‚≠ê

#### Fila 2 - Gr√°fico de Rate:
5. **Request Rate by Endpoint** - Peticiones/segundo por endpoint

#### Fila 3 - Gr√°fico Acumulativo:
6. **Cumulative Requests by Endpoint** - Requests totales acumulados

### Generar Tr√°fico para Poblar el Dashboard
```bash
# Script para generar tr√°fico
kubectl port-forward -n simple-server svc/simple-server 8081:8081 &

for i in {1..1000}; do
  curl -s http://localhost:8081/ > /dev/null
  curl -s http://localhost:8081/bye > /dev/null
  curl -s http://localhost:8081/health > /dev/null
  sleep 0.1
done
```

### Exportar Dashboard

Si haces cambios en el dashboard:

1. Click en el icono de configuraci√≥n (‚öôÔ∏è) ‚Üí **JSON Model**
2. Copia el JSON
3. Guarda en `monitoring/grafana/dashboards/simple-server-dashboard.json`

---

## üõ†Ô∏è Gu√≠a de Despliegue

### Requisitos Previos

- Docker
- Kubernetes (Minikube, Kind, K3s, o cluster real)
- kubectl configurado
- Helm 3.x
- Git

### Paso 1: Iniciar Minikube
```bash
# Iniciar con recursos suficientes
minikube start --cpus=4 --memory=8192 --driver=docker

# Habilitar addons
minikube addons enable metrics-server

# Verificar
kubectl get nodes
```

### Paso 2: Instalar Prometheus Stack
```bash
# A√±adir repo
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# Crear namespace
kubectl create namespace monitoring

# Instalar (IMPORTANTE: configurar Slack webhook antes)
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --values monitoring/kube-prometheus-stack/values.yaml

# Esperar a que todos los pods est√©n ready
kubectl get pods -n monitoring -w
```

### Paso 3: Desplegar Simple Server
```bash
# Crear namespace
kubectl create namespace simple-server

# Instalar con Helm
helm install simple-server ./helm/simple-server \
  --namespace simple-server \
  --set image.repository=ghcr.io/jpalenz77/kc-liberando-productos-practica-final \
  --set image.tag=latest \
  --set metrics.enabled=true

# Verificar
kubectl get pods -n simple-server
kubectl get svc -n simple-server
kubectl get servicemonitor -n simple-server
```

### Paso 4: Aplicar Dashboard de Grafana
```bash
# Aplicar ConfigMap con el dashboard
kubectl apply -f monitoring/grafana/simple-server-dashboard-configmap.yaml

# Verificar
kubectl get configmap -n monitoring simple-server-dashboard
```

### Paso 5: Acceder a las Interfaces
```bash
# Terminal 1: Aplicaci√≥n
kubectl port-forward -n simple-server svc/simple-server 8081:8081

# Terminal 2: Prometheus
kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090

# Terminal 3: Grafana
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80

# Terminal 4: Alertmanager
kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-alertmanager 9093:9093
```

**URLs:**
- Aplicaci√≥n: http://localhost:8081
- Prometheus: http://localhost:9090
- Grafana: http://localhost:3000 (admin / prom-operator)
- Alertmanager: http://localhost:9093

### Paso 6: Verificar que Todo Funciona
```bash
# 1. Probar endpoints
curl http://localhost:8081/
curl http://localhost:8081/bye
curl http://localhost:8081/health
curl http://localhost:8081/metrics

# 2. Verificar m√©tricas en Prometheus
# Ir a http://localhost:9090 ‚Üí Graph
# Query: server_requests_total

# 3. Ver dashboard en Grafana
# Ir a http://localhost:3000 ‚Üí Dashboards ‚Üí Simple Server - Application Metrics

# 4. Generar una alerta de prueba
kubectl scale deployment simple-server -n simple-server --replicas=0
# Esperar 2 minutos ‚Üí Deber√≠as recibir alerta en Slack
kubectl scale deployment simple-server -n simple-server --replicas=2
```

---

## üîç Troubleshooting

### Problema: Tests fallan localmente
```bash
# Soluci√≥n: Verificar entorno virtual y dependencias
python3 -m venv venv
source venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
pytest --cov -v
```

### Problema: Docker image no se construye
```bash
# Verificar Dockerfile
docker build -t simple-server:test .

# Ver logs de build
docker build -t simple-server:test . --progress=plain
```

### Problema: Pods no inician en Kubernetes
```bash
# Ver eventos del pod
kubectl describe pod -n simple-server <pod-name>

# Ver logs
kubectl logs -n simple-server <pod-name>

# Ver si hay problemas con la imagen
kubectl get events -n simple-server --sort-by='.lastTimestamp'
```

### Problema: Prometheus no encuentra targets
```bash
# Verificar ServiceMonitor
kubectl get servicemonitor -n simple-server -o yaml

# Verificar que el Service tiene el label correcto
kubectl get svc -n simple-server -o yaml

# Ver logs de Prometheus
kubectl logs -n monitoring prometheus-prometheus-kube-prometheus-prometheus-0
```

### Problema: Dashboard no aparece en Grafana
```bash
# Verificar ConfigMap
kubectl get configmap -n monitoring simple-server-dashboard

# Verificar labels
kubectl get configmap -n monitoring simple-server-dashboard -o yaml | grep labels -A 5

# Reiniciar Grafana
kubectl rollout restart deployment -n monitoring prometheus-grafana
```

### Problema: Alertas no llegan a Slack
```bash
# Verificar configuraci√≥n de Alertmanager
kubectl get secret -n monitoring alertmanager-prometheus-kube-prometheus-alertmanager -o yaml

# Ver logs de Alertmanager
kubectl logs -n monitoring alertmanager-prometheus-kube-prometheus-alertmanager-0

# Probar webhook manualmente
curl -X POST -H 'Content-type: application/json' \
  --data '{"text":"Test from curl"}' \
  YOUR_SLACK_WEBHOOK_URL
```

---

## üìö Recursos Adicionales

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Prometheus Documentation](https://prometheus.io/docs/)
- [Grafana Documentation](https://grafana.com/docs/)
- [Helm Documentation](https://helm.sh/docs/)
- [Kubernetes Documentation](https://kubernetes.io/docs/)

---

## üë§ Autor

**Juan Pablo Alenza**
- GitHub: [@jpalenz77](https://github.com/jpalenz77)
- Proyecto: KC Liberando Productos - Pr√°ctica Final

---

## üìù Licencia

Este proyecto es parte de la pr√°ctica final del curso "Liberando Productos" de KeepCoding.
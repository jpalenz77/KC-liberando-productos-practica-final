coreDns:
  enabled: true
  service:
    selector:
      k8s-app: kube-dns

kubeControllerManager:
  enabled: false

kubeEtcd:
  enabled: true
  service:
    selector:
      k8s-app: ""
      component: etcd

kubeScheduler:
  enabled: false

kubeApiServer:
  enabled: true

kubelet:
  enabled: true

kubeDns:
  enabled: false

kubeProxy:
  enabled: true

kubeStateMetrics:
  enabled: true

nodeExporter:
  enabled: true
  jobLabel: node-exporter
  serviceMonitor:
    relabelings:
      - targetLabel: job
        replacement: node-exporter

prometheus-node-exporter:
  podLabels:
    jobLabel: node-exporter
  extraArgs:
    - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
    - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$

prometheus:
  enabled: true
  prometheusSpec:
    scrapeInterval: 30s
    scrapeTimeout: 10s
    enableAdminAPI: true
    externalUrl: ""
    ruleSelectorNilUsesHelmValues: true
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false

defaultRules:
  create: true
  rules:
    alertmanager: true
    etcd: true
    configReloaders: true
    general: true
    k8s: true
    kubeApiserver: true
    kubeApiserverAvailability: true
    kubeApiserverSlos: true
    kubelet: true
    kubeProxy: true
    kubePrometheusGeneral: true
    kubePrometheusNodeRecording: true
    kubernetesApps: true
    kubernetesResources: true
    kubernetesStorage: true
    kubernetesSystem: true
    kubeScheduler: false
    kubeStateMetrics: true
    network: true
    node: true
    nodeExporterAlerting: true
    nodeExporterRecording: true
    prometheus: true
    prometheusOperator: true

## Configuration for alertmanager
alertmanager:
  enabled: true
  alertmanagerSpec:
    replicas: 1
    retention: 120h
    storage:
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 2Gi
    resources:
      requests:
        memory: 200Mi
        cpu: 100m
      limits:
        memory: 400Mi
        cpu: 200m

  config:
    global:
      resolve_timeout: 5m
      # ⚠️ IMPORTANTE: NO commitear el webhook en el repositorio
      # Se configura mediante --set durante helm install o helm upgrade:
      #   --set alertmanager.config.global.slack_api_url='https://hooks.slack.com/services/XXX/YYY/ZZZ'
      slack_api_url: ''

    route:
      receiver: 'slack-notifications'
      group_by: ['alertname', 'severity', 'namespace']
      group_wait: 10s
      group_interval: 5m
      repeat_interval: 12h
      routes:
        - matchers:
            - alertname = "Watchdog"
          receiver: 'null'
        - matchers:
            - severity =~ "critical|high"
          receiver: 'slack-notifications'
          continue: true

    inhibit_rules:
      - equal:
          - namespace
          - alertname
        source_matchers:
          - severity = critical
        target_matchers:
          - severity =~ warning|info
      - equal:
          - namespace
          - alertname
        source_matchers:
          - severity = warning
        target_matchers:
          - severity = info
      - equal:
          - namespace
        source_matchers:
          - alertname = InfoInhibitor
        target_matchers:
          - severity = info

    receivers:
      - name: 'null'

      - name: 'slack-notifications'
        slack_configs:
          - channel: '#josepalenzuela-prometheus-alarms'
            send_resolved: true
            icon_emoji: ':prometheus:'
            title: '[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] Simple Server Alert'
            title_link: 'http://localhost:9093'
            text: |-
              {{ range .Alerts }}
              *Alert:* `{{ .Labels.alertname }}`
              *Severity:* `{{ .Labels.severity | toUpper }}`
              {{ if .Annotations.summary }}*Summary:* {{ .Annotations.summary }}{{ end }}
              {{ if .Annotations.description }}*Description:* {{ .Annotations.description }}{{ end }}
              {{ if .Annotations.message }}*Message:* {{ .Annotations.message }}{{ end }}
              *Namespace:* `{{ .Labels.namespace }}`
              {{ if .Labels.pod }}*Pod:* `{{ .Labels.pod }}`{{ end }}
              {{ if .Labels.instance }}*Instance:* `{{ .Labels.instance }}`{{ end }}
              *Status:* `{{ .Status }}`
              {{ if eq .Status "firing" }}*Started:* {{ .StartsAt.Format "2006-01-02 15:04:05" }}{{ end }}
              {{ if eq .Status "resolved" }}*Resolved:* {{ .EndsAt.Format "2006-01-02 15:04:05" }}{{ end }}
              {{ end }}
            color: '{{ if eq .Status "firing" }}{{ if eq .CommonLabels.severity "critical" }}danger{{ else }}warning{{ end }}{{ else }}good{{ end }}'

    templates:
      - '/etc/alertmanager/config/*.tmpl'

prometheusOperator:
  enabled: true

## Custom Prometheus Rules for Simple Server
additionalPrometheusRulesMap:
  simple-server-rules:
    groups:
      - name: simple_server_alerts
        interval: 30s
        rules:
          # CRITICAL ALERTS
          - alert: SimpleServerDown
            expr: up{job="simple-server"} == 0
            for: 1m
            labels:
              severity: critical
            annotations:
              summary: Simple Server is down
              description: "Simple Server instance {{ $labels.instance }} has been down for more than 1 minute."
              message: "Simple Server pod {{ $labels.pod }} is DOWN and not responding"

          - alert: SimpleServerCPUThrottlingHigh
            expr: |
              rate(container_cpu_cfs_throttled_periods_total{pod=~".*simple-server.*", container="simple-server"}[5m])
              / rate(container_cpu_cfs_periods_total{pod=~".*simple-server.*", container="simple-server"}[5m]) > 0.25
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: Simple Server CPU throttling is high
              description: "Container {{ $labels.container }} in pod {{ $labels.pod }} is being throttled"
              message: "Simple Server container {{ $labels.container }} CPU throttling is {{ $value | humanizePercentage }}"

          - alert: SimpleServerConsumingMoreThanRequest
            expr: |
              avg(container_memory_usage_bytes{pod=~".*simple-server.*", container="simple-server"}) by (pod)
              > avg(kube_pod_container_resource_requests{resource="memory", pod=~".*simple-server.*", container="simple-server"}) by (pod)
            for: 2m
            labels:
              severity: critical
            annotations:
              summary: Simple Server consuming more memory than requested
              description: "Pod {{ $labels.pod }} is consuming more memory than requested"
              message: "Pod {{ $labels.pod }} memory usage exceeds the requested amount"

          - alert: SimpleServerMemoryLimitReached
            expr: |
              avg(container_memory_usage_bytes{pod=~".*simple-server.*", container="simple-server"}) by (pod)
              > avg(kube_pod_container_resource_limits{resource="memory", pod=~".*simple-server.*", container="simple-server"}) by (pod) * 0.9
            for: 1m
            labels:
              severity: critical
            annotations:
              summary: Simple Server memory limit almost reached
              description: "Pod {{ $labels.pod }} is using more than 90% of its memory limit"
              message: "Pod {{ $labels.pod }} memory usage is at {{ $value | humanizePercentage }} of limit"

          # HIGH SEVERITY ALERTS
          - alert: SimpleServerCPUConsumingMoreThanRequest
            expr: |
              avg(rate(container_cpu_usage_seconds_total{pod=~".*simple-server.*", container="simple-server"}[5m])) by (pod)
              > avg(kube_pod_container_resource_requests{resource="cpu", pod=~".*simple-server.*", container="simple-server"}) by (pod)
            for: 2m
            labels:
              severity: high
            annotations:
              summary: Simple Server CPU usage above requested
              description: "Pod {{ $labels.pod }} is consuming more CPU than requested"
              message: "Pod {{ $labels.pod }} CPU usage is {{ $value }} cores (above requested)"

          - alert: SimpleServerHighRequestRate
            expr: rate(server_requests_total[5m]) > 100
            for: 5m
            labels:
              severity: high
            annotations:
              summary: Simple Server high request rate detected
              description: "Simple Server is receiving more than 100 requests per second"
              message: "Request rate is {{ $value | humanize }} requests/second"

          - alert: SimpleServerNoRequests
            expr: rate(server_requests_total[10m]) == 0
            for: 10m
            labels:
              severity: high
            annotations:
              summary: Simple Server not receiving requests
              description: "Simple Server hasn't received any requests in the last 10 minutes"
              message: "No requests received in 10 minutes - possible connectivity issue"

          - alert: SimpleServerPodRestarting
            expr: rate(kube_pod_container_status_restarts_total{pod=~".*simple-server.*",namespace="simple-server"}[15m]) > 0
            for: 5m
            labels:
              severity: high
            annotations:
              summary: Simple Server pod is restarting
              description: "Pod {{ $labels.pod }} has restarted in the last 15 minutes"
              message: "Pod {{ $labels.pod }} is restarting frequently - check logs"

          # ADDITIONAL WORKING ALERTS
          - alert: SimpleServerScaledUp
            expr: count(up{job="simple-server"} == 1) > 2
            for: 2m
            labels:
              severity: high
            annotations:
              summary: Simple Server has scaled up
              description: "Currently {{ $value }} pods running due to high load"
              message: "Application scaled to {{ $value }} pods - high load detected"

grafana:
  enabled: true
  plugins:
    - grafana-piechart-panel

  sidecar:
    dashboards:
      enabled: true
      label: grafana_dashboard
      labelValue: "1"
      folder: /tmp/dashboards
      provider:
        foldersFromFilesStructure: true

  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: "default"
          orgId: 1
          folder: ""
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/default

  dashboards:
    default:
      node-exporter:
        gnetId: 11074
        revision: 9
        datasource: Prometheus

      node-exporter-full:
        gnetId: 1860
        revision: 29
        datasource: Prometheus

      kubernetes-cluster:
        gnetId: 7249
        revision: 1
        datasource: Prometheus

      kubernetes-pods:
        gnetId: 6417
        revision: 1
        datasource: Prometheus
